{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'fitz'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtqdm\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tqdm\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mhashlib\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mfitz\u001b[39;00m  \u001b[38;5;66;03m# PyMuPDF\u001b[39;00m\n\u001b[1;32m     12\u001b[0m sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mappend(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mabspath(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m..\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m config\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'fitz'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import openai\n",
    "from openai import OpenAI, beta\n",
    "import sys\n",
    "import json\n",
    "import pprint\n",
    "from tqdm import tqdm\n",
    "\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "from src import config\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "client = OpenAI(\n",
    "  api_key=os.getenv('OPENAI_API_KEY')\n",
    ")\n",
    "\n",
    "from docling.document_converter import DocumentConverter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Optional\n",
    "\n",
    "class Educacion(BaseModel):\n",
    "    institucion: str\n",
    "    titulo: str\n",
    "    fecha_inicio: Optional[str]\n",
    "    fecha_fin: Optional[str]\n",
    "    detalles: Optional[List[str]]\n",
    "\n",
    "class Experiencia(BaseModel):\n",
    "    empresa: str\n",
    "    ubicacion: Optional[str]\n",
    "    puesto: str\n",
    "    fecha_inicio: Optional[str]\n",
    "    fecha_fin: Optional[str]\n",
    "    responsabilidades: Optional[List[str]]\n",
    "\n",
    "class Habilidad(BaseModel):\n",
    "    nombre: str\n",
    "    nivel: Optional[str]\n",
    "\n",
    "class Idioma(BaseModel):\n",
    "    idioma: str\n",
    "    nivel: Optional[str]\n",
    "\n",
    "class Curriculum(BaseModel):\n",
    "    nombre_completo: str\n",
    "    correo: str\n",
    "    telefono: Optional[str]\n",
    "    resumen: Optional[str]\n",
    "    experiencia: List[Experiencia]\n",
    "    educacion: Optional[List[Educacion]]\n",
    "    habilidades: Optional[List[Habilidad]]\n",
    "    idiomas: Optional[List[Idioma]]\n",
    "    certificaciones: Optional[List[str]]\n",
    "    referencias: Optional[List[str]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# root_dir = config.EXTERNAL_DATA_DIR / 'cvs'\n",
    "root_dir = '/Users/ju/Library/CloudStorage/OneDrive-ESPARTINAS.A/DocumentacionEspartina/INNOVACION/Desarrollos propios/Base Datos CV Capital Humano'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "333"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_list = []\n",
    "\n",
    "for root, dirs, files in os.walk(root_dir):\n",
    "    for file in files:\n",
    "        if file.endswith('.pdf'):\n",
    "            file_path = os.path.join(root, file)\n",
    "            # print(file_path)\n",
    "            file_list.append(file_path)\n",
    "\n",
    "file_list = tuple(file_list)\n",
    "len(file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Eres un prolijo y laborioso data entry del sector de recursos humanos. Tu tarea es extaer muy detalladamente toda la información relevante de los curriculum vitae recibidos en formato pdf y pasarla prolijamente a una tabla excel con el formato dado. \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "processed = []\n",
    "id_cv = 1\n",
    "excluded_extensions = tuple(['.png', '.xlsx', '.jpeg'])\n",
    "\n",
    "\n",
    "\n",
    "# Inicializar listas para cada DataFrame\n",
    "candidatos_data = []\n",
    "experiencia_data = []\n",
    "educacion_data = []\n",
    "habilidades_data = []\n",
    "certificaciones_data = []\n",
    "\n",
    "for file_path in tqdm(file_list):\n",
    "    if not file_path.endswith(excluded_extensions):\n",
    "        print(f'Processing {file_path}')\n",
    "        try:\n",
    "            source = file_path\n",
    "            converter = DocumentConverter()\n",
    "            result = converter.convert(source)\n",
    "            result_text = result.document.export_to_markdown()\n",
    "        except Exception as e:\n",
    "            print(f'Not processed: {file_path} - error: {e}')\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            response = beta.chat.completions.parse(\n",
    "                model=\"gpt-4o-mini-2024-07-18\",\n",
    "                messages=[\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": f\"Los datos del archivo {file_path} están en formato markdown:\\n{result_text}\\n\\nPregunta: {query}\"\n",
    "                    }\n",
    "                ],\n",
    "                temperature=0,\n",
    "                max_tokens=15000,\n",
    "                response_format=Curriculum,\n",
    "                top_p=1\n",
    "            )\n",
    "\n",
    "            json_content = response.choices[0].message.content\n",
    "            data = json.loads(json_content)\n",
    "\n",
    "            candidato_id = id_cv\n",
    "            id_cv += 1\n",
    "            nombre_completo = data['nombre_completo']\n",
    "\n",
    "            # Datos generales del candidato\n",
    "            candidatos_data.append({\n",
    "                'candidato_id': candidato_id,\n",
    "                'nombre_completo': nombre_completo,\n",
    "                'correo': data['correo'],\n",
    "                'telefono': data['telefono'],\n",
    "                'resumen': data['resumen'],\n",
    "                'file_path': file_path\n",
    "            })\n",
    "\n",
    "            # Experiencia\n",
    "            for exp in data.get('experiencia', []):\n",
    "                experiencia_data.append({\n",
    "                    'candidato_id': candidato_id,\n",
    "                    'nombre_completo': nombre_completo,\n",
    "                    'empresa': exp['empresa'],\n",
    "                    'ubicacion': exp['ubicacion'],\n",
    "                    'puesto': exp['puesto'],\n",
    "                    'fecha_inicio': exp['fecha_inicio'],\n",
    "                    'fecha_fin': exp['fecha_fin'],\n",
    "                    'responsabilidades': \", \".join(exp['responsabilidades']) if exp['responsabilidades'] else None\n",
    "                })\n",
    "\n",
    "            # Educación\n",
    "            for edu in data.get('educacion', []):\n",
    "                educacion_data.append({\n",
    "                    'candidato_id': candidato_id,\n",
    "                    'nombre_completo': nombre_completo,\n",
    "                    'institucion': edu['institucion'],\n",
    "                    'titulo': edu['titulo'],\n",
    "                    'fecha_inicio': edu['fecha_inicio'],\n",
    "                    'fecha_fin': edu['fecha_fin'],\n",
    "                    'detalles': \", \".join(edu['detalles']) if edu['detalles'] else None\n",
    "                })\n",
    "\n",
    "            # Habilidades\n",
    "            for hab in data.get('habilidades', []):\n",
    "                habilidades_data.append({\n",
    "                    'candidato_id': candidato_id,\n",
    "                    'nombre_completo': nombre_completo,\n",
    "                    'nombre': hab['nombre'],\n",
    "                    'nivel': hab['nivel']\n",
    "                })\n",
    "\n",
    "            # Certificaciones\n",
    "            if data.get('certificaciones'):\n",
    "                for cert in data['certificaciones']:\n",
    "                    certificaciones_data.append({\n",
    "                        'candidato_id': candidato_id,\n",
    "                        'nombre_completo': nombre_completo,\n",
    "                        'certificacion': cert\n",
    "                    })\n",
    "\n",
    "            processed.append(file_path)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f'Error processing {file_path}: {e}')\n",
    "\n",
    "# Crear los DataFrames finales\n",
    "candidatos_df = pd.DataFrame(candidatos_data)\n",
    "candidatos_df['zona/area'] = candidatos_df['file_path'].str.split('/', expand=True)[10]\n",
    "candidatos_df = candidatos_df[['candidato_id', 'zona/area', 'nombre_completo', 'correo', 'telefono', 'resumen', 'file_path']]\n",
    "\n",
    "\n",
    "experiencia_df = pd.DataFrame(experiencia_data)\n",
    "experiencia_df['anio_inicio'] = experiencia_df['fecha_inicio'].str.extract(r'(\\d{4})')\n",
    "experiencia_df.nombre_completo = experiencia_df.nombre_completo.str.title()\n",
    "experiencia_df = experiencia_df[['candidato_id', 'nombre_completo', 'empresa', 'ubicacion', 'puesto', 'anio_inicio', 'fecha_inicio', 'fecha_fin', 'responsabilidades']]\n",
    "\n",
    "\n",
    "educacion_df = pd.DataFrame(educacion_data)\n",
    "educacion_df.nombre_completo = educacion_df.nombre_completo.str.title()\n",
    "educacion_df['anio_inicio'] = educacion_df['fecha_inicio'].str.extract(r'(\\d{4})')\n",
    "educacion_df = educacion_df[['candidato_id', 'nombre_completo', 'institucion', 'titulo', 'anio_inicio', 'fecha_inicio', 'fecha_fin', 'detalles']]\n",
    "\n",
    "\n",
    "habilidades_df = pd.DataFrame(habilidades_data)\n",
    "habilidades_df.nombre_completo = habilidades_df.nombre_completo.str.title()\n",
    "\n",
    "\n",
    "certificaciones_df = pd.DataFrame(certificaciones_data)\n",
    "certificaciones_df.nombre_completo = certificaciones_df.nombre_completo.str.title()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.ExcelWriter(f'{root_dir}/base_cv_capital_humano.xlsx') as writer:\n",
    "    candidatos_df.to_excel(writer, sheet_name='Candidatos', index=False)\n",
    "    experiencia_df.to_excel(writer, sheet_name='Experiencia', index=False)\n",
    "    educacion_df.to_excel(writer, sheet_name='Educacion', index=False)\n",
    "    habilidades_df.to_excel(writer, sheet_name='Habilidades', index=False)\n",
    "    certificaciones_df.to_excel(writer, sheet_name='Certificaciones', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
