{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import openai\n",
    "from openai import OpenAI, beta\n",
    "import sys\n",
    "import json\n",
    "import pprint\n",
    "from tqdm import tqdm\n",
    "import hashlib\n",
    "from pathlib import Path\n",
    "\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "from src import config\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "client = OpenAI(\n",
    "  api_key=os.getenv('OPENAI_API_KEY')\n",
    ")\n",
    "\n",
    "from docling.document_converter import DocumentConverter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "HASHES_FILE = \".hashes.txt\"\n",
    "\n",
    "def calculate_file_hash(file_path):\n",
    "    \"\"\"Generate a SHA-256 hash of the entire file contents (binary).\"\"\"\n",
    "    hash_sha256 = hashlib.sha256()\n",
    "    \n",
    "    with open(file_path, \"rb\") as f:\n",
    "        for chunk in iter(lambda: f.read(8192), b\"\"):\n",
    "            hash_sha256.update(chunk)\n",
    "    \n",
    "    return hash_sha256.hexdigest()\n",
    "\n",
    "def load_existing_hashes():\n",
    "    \"\"\"Load previously processed hashes from file.\"\"\"\n",
    "    if not os.path.exists(HASHES_FILE):\n",
    "        return set()\n",
    "    \n",
    "    with open(HASHES_FILE, \"r\") as f:\n",
    "        return set(line.strip() for line in f)\n",
    "\n",
    "def save_hash(hash_value):\n",
    "    \"\"\"Save a new hash to the file.\"\"\"\n",
    "    with open(HASHES_FILE, \"a\") as f:\n",
    "        f.write(hash_value + \"\\n\")\n",
    "\n",
    "def process_pdf(file_path, force=False):\n",
    "    \"\"\"Check if a PDF has already been processed, if not (or if forced), process and save the hash.\"\"\"\n",
    "    file_hash = calculate_file_hash(file_path)\n",
    "    existing_hashes = load_existing_hashes()\n",
    "\n",
    "    if not force and file_hash in existing_hashes:\n",
    "        # print(f\"Skipping file {file_path}, it has already been processed.\")\n",
    "        return False\n",
    "\n",
    "    print(f\"Processing and saving hash for {file_path}.\")\n",
    "    # Aquí iría el código de procesamiento real del PDF\n",
    "    save_hash(file_hash)\n",
    "\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Optional\n",
    "\n",
    "class Educacion(BaseModel):\n",
    "    institucion: str\n",
    "    titulo: str\n",
    "    fecha_inicio: Optional[str]\n",
    "    fecha_fin: Optional[str]\n",
    "    detalles: Optional[List[str]]\n",
    "\n",
    "class Experiencia(BaseModel):\n",
    "    empresa: str\n",
    "    ubicacion: Optional[str]\n",
    "    puesto: str\n",
    "    fecha_inicio: Optional[str]\n",
    "    fecha_fin: Optional[str]\n",
    "    responsabilidades: Optional[List[str]]\n",
    "\n",
    "class Habilidad(BaseModel):\n",
    "    nombre: str\n",
    "    nivel: Optional[str]\n",
    "\n",
    "class Idioma(BaseModel):\n",
    "    idioma: str\n",
    "    nivel: Optional[str]\n",
    "\n",
    "class Curriculum(BaseModel):\n",
    "    nombre_completo: str\n",
    "    correo: str\n",
    "    telefono: Optional[str]\n",
    "    resumen: Optional[str]\n",
    "    experiencia: List[Experiencia]\n",
    "    educacion: Optional[List[Educacion]]\n",
    "    habilidades: Optional[List[Habilidad]]\n",
    "    idiomas: Optional[List[Idioma]]\n",
    "    certificaciones: Optional[List[str]]\n",
    "    referencias: Optional[List[str]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# root_dir = config.EXTERNAL_DATA_DIR / 'cvs'\n",
    "root_dir = '/Users/ju/Library/CloudStorage/OneDrive-ESPARTINAS.A/DocumentacionEspartina/INNOVACION/Desarrollos propios/Base Datos CV Capital Humano'\n",
    "output_name = 'base_cv_capital_humano.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = []\n",
    "\n",
    "for root, dirs, files in os.walk(root_dir):\n",
    "    for file in files:\n",
    "        if file.endswith('.pdf'):\n",
    "            file_path = os.path.join(root, file)\n",
    "            # print(file_path)\n",
    "            file_list.append(file_path)\n",
    "\n",
    "file_list = tuple(file_list)\n",
    "len(file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Eres un prolijo y laborioso data entry del sector de recursos humanos. Tu tarea es extaer muy detalladamente toda la información relevante de los curriculum vitae recibidos en formato pdf y pasarla prolijamente a una tabla excel con el formato dado. \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "excel_path = os.path.join(root_dir, output_name)\n",
    "# Expected sheet names\n",
    "expected_sheets = ['Candidatos', 'Experiencia', 'Educacion', 'Habilidades', 'Certificaciones']\n",
    "\n",
    "# Read all available sheets\n",
    "all_sheets = pd.read_excel(excel_path, sheet_name=None)\n",
    "loaded_dfs = {}\n",
    "\n",
    "# Check and load only the sheets that exist\n",
    "for sheet in expected_sheets:\n",
    "    if sheet in all_sheets:\n",
    "        loaded_dfs[sheet] = all_sheets[sheet]\n",
    "    else:\n",
    "        print(f'Warning: Sheet \"{sheet}\" is not present in the file.')\n",
    "\n",
    "candidatos_df = loaded_dfs.get('Candidatos')\n",
    "experiencia_df = loaded_dfs.get('Experiencia')\n",
    "educacion_df = loaded_dfs.get('Educacion')\n",
    "habilidades_df = loaded_dfs.get('Habilidades')\n",
    "certificaciones_df = loaded_dfs.get('Certificaciones')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed = []\n",
    "id_cv = candidatos_df.candidato_id.max() + 1\n",
    "excluded_extensions = tuple(['.png', '.xlsx', '.jpeg'])\n",
    "\n",
    "# Initialize lists for each DataFrame\n",
    "candidatos_data = []\n",
    "experiencia_data = []\n",
    "educacion_data = []\n",
    "habilidades_data = []\n",
    "certificaciones_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file_path in tqdm(file_list):\n",
    "    if not file_path.endswith(excluded_extensions):\n",
    "        if process_pdf(file_path=file_path):\n",
    "            try:\n",
    "                source = file_path\n",
    "                converter = DocumentConverter()\n",
    "                result = converter.convert(source)\n",
    "                result_text = result.document.export_to_markdown()\n",
    "            except Exception as e:\n",
    "                print(f'Not processed: {file_path} - error: {e}')\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                response = beta.chat.completions.parse(\n",
    "                    model=\"gpt-4o-mini-2024-07-18\",\n",
    "                    messages=[\n",
    "                        {\n",
    "                            \"role\": \"user\",\n",
    "                            \"content\": f\"Los datos del archivo {file_path} están en formato markdown:\\n{result_text}\\n\\nPregunta: {query}\"\n",
    "                        }\n",
    "                    ],\n",
    "                    temperature=0,\n",
    "                    max_tokens=15000,\n",
    "                    response_format=Curriculum,\n",
    "                    top_p=1\n",
    "                )\n",
    "\n",
    "                json_content = response.choices[0].message.content\n",
    "                data = json.loads(json_content)\n",
    "\n",
    "                candidato_id = id_cv\n",
    "                id_cv += 1\n",
    "                nombre_completo = data['nombre_completo']\n",
    "\n",
    "                # Datos generales del candidato\n",
    "                candidatos_data.append({\n",
    "                    'candidato_id': candidato_id,\n",
    "                    'nombre_completo': nombre_completo,\n",
    "                    'correo': data['correo'],\n",
    "                    'telefono': data['telefono'],\n",
    "                    'resumen': data['resumen'],\n",
    "                    'file_path': file_path\n",
    "                })\n",
    "\n",
    "                # Experiencia\n",
    "                for exp in data.get('experiencia', []):\n",
    "                    experiencia_data.append({\n",
    "                        'candidato_id': candidato_id,\n",
    "                        'nombre_completo': nombre_completo,\n",
    "                        'empresa': exp['empresa'],\n",
    "                        'ubicacion': exp['ubicacion'],\n",
    "                        'puesto': exp['puesto'],\n",
    "                        'fecha_inicio': exp['fecha_inicio'],\n",
    "                        'fecha_fin': exp['fecha_fin'],\n",
    "                        'responsabilidades': \", \".join(exp['responsabilidades']) if exp['responsabilidades'] else None\n",
    "                    })\n",
    "\n",
    "                # Educación\n",
    "                for edu in data.get('educacion', []):\n",
    "                    educacion_data.append({\n",
    "                        'candidato_id': candidato_id,\n",
    "                        'nombre_completo': nombre_completo,\n",
    "                        'institucion': edu['institucion'],\n",
    "                        'titulo': edu['titulo'],\n",
    "                        'fecha_inicio': edu['fecha_inicio'],\n",
    "                        'fecha_fin': edu['fecha_fin'],\n",
    "                        'detalles': \", \".join(edu['detalles']) if edu['detalles'] else None\n",
    "                    })\n",
    "\n",
    "                # Habilidades\n",
    "                for hab in data.get('habilidades', []):\n",
    "                    habilidades_data.append({\n",
    "                        'candidato_id': candidato_id,\n",
    "                        'nombre_completo': nombre_completo,\n",
    "                        'nombre': hab['nombre'],\n",
    "                        'nivel': hab['nivel']\n",
    "                    })\n",
    "\n",
    "                # Certificaciones\n",
    "                if data.get('certificaciones'):\n",
    "                    for cert in data['certificaciones']:\n",
    "                        certificaciones_data.append({\n",
    "                            'candidato_id': candidato_id,\n",
    "                            'nombre_completo': nombre_completo,\n",
    "                            'certificacion': cert\n",
    "                        })\n",
    "\n",
    "                processed.append(file_path)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f'Error processing {file_path}: {e}')\n",
    "\n",
    "\n",
    "if candidatos_data:\n",
    "    # Candidates\n",
    "    candidatos_df_actual = pd.DataFrame(candidatos_data)\n",
    "    candidatos_df_actual['zona/area'] = candidatos_df_actual['file_path'].str.split('/', expand=True)[10]\n",
    "    candidatos_df_actual = candidatos_df_actual[['candidato_id', 'nombre_completo', 'zona/area', 'correo', 'telefono', 'resumen', 'file_path']]\n",
    "\n",
    "    # Experience\n",
    "    if not experiencia_data:\n",
    "        experiencia_df_actual = pd.DataFrame(columns=['candidato_id', 'nombre_completo', 'empresa', 'ubicacion', 'puesto', 'anio_inicio', 'fecha_inicio', 'fecha_fin', 'responsabilidades'])\n",
    "    else:\n",
    "        experiencia_df_actual = pd.DataFrame(experiencia_data)\n",
    "        if 'fecha_inicio' in experiencia_df_actual.columns:\n",
    "            experiencia_df_actual['anio_inicio'] = experiencia_df_actual['fecha_inicio'].str.extract(r'(\\d{4})')\n",
    "        if 'nombre_completo' in experiencia_df_actual.columns:\n",
    "            experiencia_df_actual.nombre_completo = experiencia_df_actual.nombre_completo.str.title()\n",
    "        experiencia_df_actual = experiencia_df_actual[['candidato_id', 'nombre_completo', 'empresa', 'ubicacion', 'puesto', 'anio_inicio', 'fecha_inicio', 'fecha_fin', 'responsabilidades']]\n",
    "\n",
    "    # Education\n",
    "    if not educacion_data:\n",
    "        educacion_df_actual = pd.DataFrame(columns=['candidato_id', 'nombre_completo', 'institucion', 'titulo', 'anio_inicio', 'fecha_inicio', 'fecha_fin', 'detalles'])\n",
    "    else:\n",
    "        educacion_df_actual = pd.DataFrame(educacion_data)\n",
    "        if 'nombre_completo' in educacion_df_actual.columns:\n",
    "            educacion_df_actual.nombre_completo = educacion_df_actual.nombre_completo.str.title()\n",
    "        if 'fecha_inicio' in educacion_df_actual.columns:\n",
    "            educacion_df_actual['anio_inicio'] = educacion_df_actual['fecha_inicio'].str.extract(r'(\\d{4})')\n",
    "        educacion_df_actual = educacion_df_actual[['candidato_id', 'nombre_completo', 'institucion', 'titulo', 'anio_inicio', 'fecha_inicio', 'fecha_fin', 'detalles']]\n",
    "\n",
    "    # Skills\n",
    "    if not habilidades_data:\n",
    "        habilidades_df_actual = pd.DataFrame(columns=['candidato_id', 'nombre_completo', 'nombre', 'nivel'])\n",
    "    else:\n",
    "        habilidades_df_actual = pd.DataFrame(habilidades_data)\n",
    "        if 'nombre_completo' in habilidades_df_actual.columns:\n",
    "            habilidades_df_actual.nombre_completo = habilidades_df_actual.nombre_completo.str.title()\n",
    "\n",
    "    # Certifications\n",
    "    if not certificaciones_data:\n",
    "        certificaciones_df_actual = pd.DataFrame(columns=['candidato_id', 'nombre_completo', 'certificacion'])\n",
    "    else:\n",
    "        certificaciones_df_actual = pd.DataFrame(certificaciones_data)\n",
    "        if 'nombre_completo' in certificaciones_df_actual.columns:\n",
    "            certificaciones_df_actual.nombre_completo = certificaciones_df_actual.nombre_completo.str.title()\n",
    "\n",
    "    # Concatenate with existing DataFrames\n",
    "    candidatos_df = pd.concat([candidatos_df, candidatos_df_actual], ignore_index=True)\n",
    "    experiencia_df = pd.concat([experiencia_df, experiencia_df_actual], ignore_index=True)\n",
    "    educacion_df = pd.concat([educacion_df, educacion_df_actual], ignore_index=True)\n",
    "    habilidades_df = pd.concat([habilidades_df, habilidades_df_actual], ignore_index=True)\n",
    "    certificaciones_df = pd.concat([certificaciones_df, certificaciones_df_actual], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openpyxl import load_workbook\n",
    "from openpyxl.styles import Font\n",
    "from openpyxl.utils import get_column_letter\n",
    "\n",
    "# Ruta de exportación\n",
    "excel_path = f'{root_dir}/base_cv_capital_humano.xlsx'\n",
    "\n",
    "# Guardar los DataFrames en un Excel\n",
    "with pd.ExcelWriter(excel_path, engine='openpyxl') as writer:\n",
    "    candidatos_df.to_excel(writer, sheet_name='Candidatos', index=False)\n",
    "    experiencia_df.to_excel(writer, sheet_name='Experiencia', index=False)\n",
    "    educacion_df.to_excel(writer, sheet_name='Educacion', index=False)\n",
    "    habilidades_df.to_excel(writer, sheet_name='Habilidades', index=False)\n",
    "    certificaciones_df.to_excel(writer, sheet_name='Certificaciones', index=False)\n",
    "\n",
    "# Volver a abrir el archivo para aplicar estilos\n",
    "workbook = load_workbook(excel_path)\n",
    "bold_font = Font(bold=True)\n",
    "\n",
    "for sheet_name in workbook.sheetnames:\n",
    "    sheet = workbook[sheet_name]\n",
    "\n",
    "    # Fijar primera fila y dos primeras columnas\n",
    "    sheet.freeze_panes = 'C2'  # Fila 1 y columnas A-B quedan fijas\n",
    "\n",
    "    # Poner en negrita la primera fila\n",
    "    for cell in sheet[1]:\n",
    "        cell.font = bold_font\n",
    "\n",
    "    # Ajustar ancho de columnas al contenido\n",
    "    for col_idx, col in enumerate(sheet.columns, 1):\n",
    "        max_length = 0\n",
    "        for cell in col:\n",
    "            try:\n",
    "                if cell.value:\n",
    "                    max_length = max(max_length, len(str(cell.value)))\n",
    "            except:\n",
    "                pass\n",
    "        adjusted_width = max_length + 2\n",
    "        sheet.column_dimensions[get_column_letter(col_idx)].width = adjusted_width\n",
    "\n",
    "# Guardar cambios\n",
    "workbook.save(excel_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
